{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/saranyak/Desktop/GT/Fall2023/ComputationalDataAnalytics/Project/GenreClassification/Preprocessing/Output/NotEncoded_Genres_ArtistsEncoded/p%ofgenre/Train.csv')\n",
    "test_df = pd.read_csv('/Users/saranyak/Desktop/GT/Fall2023/ComputationalDataAnalytics/Project/GenreClassification/Preprocessing/Output/NotEncoded_Genres_ArtistsEncoded/p%ofgenre/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['genres'])\n",
    "y_train = train_df['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=['genres'])\n",
    "y_test = test_df['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "      <th>Artists_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18629</th>\n",
       "      <td>0.152514</td>\n",
       "      <td>0.684118</td>\n",
       "      <td>292790.588235</td>\n",
       "      <td>0.582059</td>\n",
       "      <td>2.512353e-06</td>\n",
       "      <td>0.324165</td>\n",
       "      <td>-11.494706</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>119.951000</td>\n",
       "      <td>0.635824</td>\n",
       "      <td>46.647059</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>0.110815</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>270396.625000</td>\n",
       "      <td>0.734875</td>\n",
       "      <td>1.022312e-04</td>\n",
       "      <td>0.069687</td>\n",
       "      <td>-10.153500</td>\n",
       "      <td>0.035987</td>\n",
       "      <td>125.001875</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>0.511591</td>\n",
       "      <td>0.639217</td>\n",
       "      <td>208689.260870</td>\n",
       "      <td>0.534348</td>\n",
       "      <td>5.304348e-07</td>\n",
       "      <td>0.187648</td>\n",
       "      <td>-8.348304</td>\n",
       "      <td>0.034348</td>\n",
       "      <td>129.692391</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>39.695652</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18913</th>\n",
       "      <td>0.088451</td>\n",
       "      <td>0.663519</td>\n",
       "      <td>206259.092593</td>\n",
       "      <td>0.716407</td>\n",
       "      <td>1.901248e-04</td>\n",
       "      <td>0.192709</td>\n",
       "      <td>-5.128296</td>\n",
       "      <td>0.101763</td>\n",
       "      <td>115.466852</td>\n",
       "      <td>0.624815</td>\n",
       "      <td>64.648148</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11081</th>\n",
       "      <td>0.395750</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>261716.500000</td>\n",
       "      <td>0.805250</td>\n",
       "      <td>2.145575e-01</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>-7.381750</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>111.086000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>269133.000000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>-8.830000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>119.064000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>0.239708</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>231926.886598</td>\n",
       "      <td>0.738402</td>\n",
       "      <td>1.943326e-04</td>\n",
       "      <td>0.170296</td>\n",
       "      <td>-4.753938</td>\n",
       "      <td>0.097689</td>\n",
       "      <td>127.830938</td>\n",
       "      <td>0.668474</td>\n",
       "      <td>60.010309</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.699550</td>\n",
       "      <td>0.318850</td>\n",
       "      <td>160508.800000</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>5.105340e-04</td>\n",
       "      <td>0.157735</td>\n",
       "      <td>-12.201400</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>111.960400</td>\n",
       "      <td>0.397020</td>\n",
       "      <td>21.850000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>307440.000000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>1.510000e-03</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>-9.883000</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>87.900000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.277025</td>\n",
       "      <td>0.657295</td>\n",
       "      <td>286047.636364</td>\n",
       "      <td>0.498977</td>\n",
       "      <td>1.040000e-06</td>\n",
       "      <td>0.151902</td>\n",
       "      <td>-8.049750</td>\n",
       "      <td>0.058857</td>\n",
       "      <td>114.262727</td>\n",
       "      <td>0.468614</td>\n",
       "      <td>42.613636</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability    duration_ms    energy  instrumentalness  \\\n",
       "18629      0.152514      0.684118  292790.588235  0.582059      2.512353e-06   \n",
       "7256       0.110815      0.639500  270396.625000  0.734875      1.022312e-04   \n",
       "6407       0.511591      0.639217  208689.260870  0.534348      5.304348e-07   \n",
       "18913      0.088451      0.663519  206259.092593  0.716407      1.901248e-04   \n",
       "11081      0.395750      0.472500  261716.500000  0.805250      2.145575e-01   \n",
       "...             ...           ...            ...       ...               ...   \n",
       "11284      0.855000      0.631000  269133.000000  0.324000      0.000000e+00   \n",
       "11964      0.239708      0.754515  231926.886598  0.738402      1.943326e-04   \n",
       "5390       0.699550      0.318850  160508.800000  0.330200      5.105340e-04   \n",
       "860        0.128000      0.819000  307440.000000  0.428000      1.510000e-03   \n",
       "15795      0.277025      0.657295  286047.636364  0.498977      1.040000e-06   \n",
       "\n",
       "       liveness   loudness  speechiness       tempo   valence  popularity  \\\n",
       "18629  0.324165 -11.494706     0.085300  119.951000  0.635824   46.647059   \n",
       "7256   0.069687 -10.153500     0.035987  125.001875  0.673000   40.750000   \n",
       "6407   0.187648  -8.348304     0.034348  129.692391  0.496304   39.695652   \n",
       "18913  0.192709  -5.128296     0.101763  115.466852  0.624815   64.648148   \n",
       "11081  0.158300  -7.381750     0.041600  111.086000  0.694000   36.250000   \n",
       "...         ...        ...          ...         ...       ...         ...   \n",
       "11284  0.074200  -8.830000     0.042500  119.064000  0.447000   57.000000   \n",
       "11964  0.170296  -4.753938     0.097689  127.830938  0.668474   60.010309   \n",
       "5390   0.157735 -12.201400     0.035920  111.960400  0.397020   21.850000   \n",
       "860    0.211000  -9.883000     0.317000   87.900000  0.454000   55.000000   \n",
       "15795  0.151902  -8.049750     0.058857  114.262727  0.468614   42.613636   \n",
       "\n",
       "       key  mode  count  Artists_encoded  \n",
       "18629    5     0     34             4093  \n",
       "7256     4     1     16              795  \n",
       "6407     4     1     46             2240  \n",
       "18913    0     1     54             3886  \n",
       "11081    7     1      8              777  \n",
       "...    ...   ...    ...              ...  \n",
       "11284    4     1      2             4718  \n",
       "11964    7     0     97             6250  \n",
       "5390     7     1     40             3776  \n",
       "860      5     0      1             6487  \n",
       "15795    9     0     44             2425  \n",
       "\n",
       "[15310 rows x 15 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "      <th>Artists_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15671</th>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>252424.000000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.113356</td>\n",
       "      <td>0.349813</td>\n",
       "      <td>-4.203875</td>\n",
       "      <td>0.081638</td>\n",
       "      <td>119.750250</td>\n",
       "      <td>0.463250</td>\n",
       "      <td>50.375000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>0.665833</td>\n",
       "      <td>0.527667</td>\n",
       "      <td>149444.500000</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>0.201406</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>-16.250167</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>127.041833</td>\n",
       "      <td>0.485167</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>209716.500000</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172250</td>\n",
       "      <td>-6.244500</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>114.480500</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>0.858064</td>\n",
       "      <td>0.408936</td>\n",
       "      <td>157726.961538</td>\n",
       "      <td>0.312526</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.198821</td>\n",
       "      <td>-11.307974</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>93.516936</td>\n",
       "      <td>0.423154</td>\n",
       "      <td>28.756410</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17360</th>\n",
       "      <td>0.075053</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>246726.750000</td>\n",
       "      <td>0.550625</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.149375</td>\n",
       "      <td>-14.332375</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>122.263625</td>\n",
       "      <td>0.821625</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10156</th>\n",
       "      <td>0.837560</td>\n",
       "      <td>0.244669</td>\n",
       "      <td>294471.941292</td>\n",
       "      <td>0.198553</td>\n",
       "      <td>0.731984</td>\n",
       "      <td>0.168493</td>\n",
       "      <td>-19.996155</td>\n",
       "      <td>0.045730</td>\n",
       "      <td>103.934483</td>\n",
       "      <td>0.141831</td>\n",
       "      <td>28.512720</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>5054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.334891</td>\n",
       "      <td>0.503174</td>\n",
       "      <td>200183.434783</td>\n",
       "      <td>0.499609</td>\n",
       "      <td>0.117946</td>\n",
       "      <td>0.160704</td>\n",
       "      <td>-7.466087</td>\n",
       "      <td>0.083709</td>\n",
       "      <td>103.786435</td>\n",
       "      <td>0.286826</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>249600.000000</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>-2.299000</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>100.005000</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>155199.666667</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159133</td>\n",
       "      <td>-6.340333</td>\n",
       "      <td>0.068633</td>\n",
       "      <td>166.578000</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>0.139192</td>\n",
       "      <td>0.813667</td>\n",
       "      <td>213884.000000</td>\n",
       "      <td>0.617667</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.170267</td>\n",
       "      <td>-6.025500</td>\n",
       "      <td>0.118942</td>\n",
       "      <td>117.549167</td>\n",
       "      <td>0.473350</td>\n",
       "      <td>59.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5104 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability    duration_ms    energy  instrumentalness  \\\n",
       "15671      0.011463      0.560000  252424.000000  0.884000          0.113356   \n",
       "8048       0.665833      0.527667  149444.500000  0.270500          0.201406   \n",
       "7153       0.318000      0.531000  209716.500000  0.615500          0.000000   \n",
       "1087       0.858064      0.408936  157726.961538  0.312526          0.001029   \n",
       "17360      0.075053      0.668125  246726.750000  0.550625          0.000902   \n",
       "...             ...           ...            ...       ...               ...   \n",
       "10156      0.837560      0.244669  294471.941292  0.198553          0.731984   \n",
       "252        0.334891      0.503174  200183.434783  0.499609          0.117946   \n",
       "6876       0.000148      0.665000  249600.000000  0.913000          0.412000   \n",
       "511        0.005470      0.407000  155199.666667  0.799000          0.000000   \n",
       "5456       0.139192      0.813667  213884.000000  0.617667          0.011494   \n",
       "\n",
       "       liveness   loudness  speechiness       tempo   valence  popularity  \\\n",
       "15671  0.349813  -4.203875     0.081638  119.750250  0.463250   50.375000   \n",
       "8048   0.084183 -16.250167     0.037000  127.041833  0.485167   10.500000   \n",
       "7153   0.172250  -6.244500     0.126450  114.480500  0.474500   63.500000   \n",
       "1087   0.198821 -11.307974     0.032046   93.516936  0.423154   28.756410   \n",
       "17360  0.149375 -14.332375     0.037012  122.263625  0.821625   32.500000   \n",
       "...         ...        ...          ...         ...       ...         ...   \n",
       "10156  0.168493 -19.996155     0.045730  103.934483  0.141831   28.512720   \n",
       "252    0.160704  -7.466087     0.083709  103.786435  0.286826   72.000000   \n",
       "6876   0.384000  -2.299000     0.046100  100.005000  0.439000   51.000000   \n",
       "511    0.159133  -6.340333     0.068633  166.578000  0.590667   51.666667   \n",
       "5456   0.170267  -6.025500     0.118942  117.549167  0.473350   59.083333   \n",
       "\n",
       "       key  mode  count  Artists_encoded  \n",
       "15671    2     1     16             1263  \n",
       "8048     9     1     12             7431  \n",
       "7153     2     1      2             7602  \n",
       "1087     3     1    156             8494  \n",
       "17360    9     1     16             6274  \n",
       "...    ...   ...    ...              ...  \n",
       "10156    0     1    511             5054  \n",
       "252      5     1     23             4755  \n",
       "6876     1     1      2             2316  \n",
       "511      7     1      6             2406  \n",
       "5456     0     1     12             7574  \n",
       "\n",
       "[5104 rows x 15 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_encoded_train = X_train[['Artists_encoded','key','mode']]\n",
    "artists_encoded_valid = X_valid[['Artists_encoded','key','mode']]\n",
    "artists_encoded_test = X_test[['Artists_encoded','key','mode']]\n",
    "X_train = X_train.drop(columns=['Artists_encoded','key','mode'])\n",
    "X_valid = X_valid.drop(columns=['Artists_encoded','key','mode'])\n",
    "X_test = X_test.drop(columns=['Artists_encoded','key','mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18629</th>\n",
       "      <td>0.152514</td>\n",
       "      <td>0.684118</td>\n",
       "      <td>292790.588235</td>\n",
       "      <td>0.582059</td>\n",
       "      <td>2.512353e-06</td>\n",
       "      <td>0.324165</td>\n",
       "      <td>-11.494706</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>119.951000</td>\n",
       "      <td>0.635824</td>\n",
       "      <td>46.647059</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>0.110815</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>270396.625000</td>\n",
       "      <td>0.734875</td>\n",
       "      <td>1.022312e-04</td>\n",
       "      <td>0.069687</td>\n",
       "      <td>-10.153500</td>\n",
       "      <td>0.035987</td>\n",
       "      <td>125.001875</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>0.511591</td>\n",
       "      <td>0.639217</td>\n",
       "      <td>208689.260870</td>\n",
       "      <td>0.534348</td>\n",
       "      <td>5.304348e-07</td>\n",
       "      <td>0.187648</td>\n",
       "      <td>-8.348304</td>\n",
       "      <td>0.034348</td>\n",
       "      <td>129.692391</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>39.695652</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18913</th>\n",
       "      <td>0.088451</td>\n",
       "      <td>0.663519</td>\n",
       "      <td>206259.092593</td>\n",
       "      <td>0.716407</td>\n",
       "      <td>1.901248e-04</td>\n",
       "      <td>0.192709</td>\n",
       "      <td>-5.128296</td>\n",
       "      <td>0.101763</td>\n",
       "      <td>115.466852</td>\n",
       "      <td>0.624815</td>\n",
       "      <td>64.648148</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11081</th>\n",
       "      <td>0.395750</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>261716.500000</td>\n",
       "      <td>0.805250</td>\n",
       "      <td>2.145575e-01</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>-7.381750</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>111.086000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>269133.000000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>-8.830000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>119.064000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>0.239708</td>\n",
       "      <td>0.754515</td>\n",
       "      <td>231926.886598</td>\n",
       "      <td>0.738402</td>\n",
       "      <td>1.943326e-04</td>\n",
       "      <td>0.170296</td>\n",
       "      <td>-4.753938</td>\n",
       "      <td>0.097689</td>\n",
       "      <td>127.830938</td>\n",
       "      <td>0.668474</td>\n",
       "      <td>60.010309</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.699550</td>\n",
       "      <td>0.318850</td>\n",
       "      <td>160508.800000</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>5.105340e-04</td>\n",
       "      <td>0.157735</td>\n",
       "      <td>-12.201400</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>111.960400</td>\n",
       "      <td>0.397020</td>\n",
       "      <td>21.850000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>307440.000000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>1.510000e-03</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>-9.883000</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>87.900000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.277025</td>\n",
       "      <td>0.657295</td>\n",
       "      <td>286047.636364</td>\n",
       "      <td>0.498977</td>\n",
       "      <td>1.040000e-06</td>\n",
       "      <td>0.151902</td>\n",
       "      <td>-8.049750</td>\n",
       "      <td>0.058857</td>\n",
       "      <td>114.262727</td>\n",
       "      <td>0.468614</td>\n",
       "      <td>42.613636</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability    duration_ms    energy  instrumentalness  \\\n",
       "18629      0.152514      0.684118  292790.588235  0.582059      2.512353e-06   \n",
       "7256       0.110815      0.639500  270396.625000  0.734875      1.022312e-04   \n",
       "6407       0.511591      0.639217  208689.260870  0.534348      5.304348e-07   \n",
       "18913      0.088451      0.663519  206259.092593  0.716407      1.901248e-04   \n",
       "11081      0.395750      0.472500  261716.500000  0.805250      2.145575e-01   \n",
       "...             ...           ...            ...       ...               ...   \n",
       "11284      0.855000      0.631000  269133.000000  0.324000      0.000000e+00   \n",
       "11964      0.239708      0.754515  231926.886598  0.738402      1.943326e-04   \n",
       "5390       0.699550      0.318850  160508.800000  0.330200      5.105340e-04   \n",
       "860        0.128000      0.819000  307440.000000  0.428000      1.510000e-03   \n",
       "15795      0.277025      0.657295  286047.636364  0.498977      1.040000e-06   \n",
       "\n",
       "       liveness   loudness  speechiness       tempo   valence  popularity  \\\n",
       "18629  0.324165 -11.494706     0.085300  119.951000  0.635824   46.647059   \n",
       "7256   0.069687 -10.153500     0.035987  125.001875  0.673000   40.750000   \n",
       "6407   0.187648  -8.348304     0.034348  129.692391  0.496304   39.695652   \n",
       "18913  0.192709  -5.128296     0.101763  115.466852  0.624815   64.648148   \n",
       "11081  0.158300  -7.381750     0.041600  111.086000  0.694000   36.250000   \n",
       "...         ...        ...          ...         ...       ...         ...   \n",
       "11284  0.074200  -8.830000     0.042500  119.064000  0.447000   57.000000   \n",
       "11964  0.170296  -4.753938     0.097689  127.830938  0.668474   60.010309   \n",
       "5390   0.157735 -12.201400     0.035920  111.960400  0.397020   21.850000   \n",
       "860    0.211000  -9.883000     0.317000   87.900000  0.454000   55.000000   \n",
       "15795  0.151902  -8.049750     0.058857  114.262727  0.468614   42.613636   \n",
       "\n",
       "       count  \n",
       "18629     34  \n",
       "7256      16  \n",
       "6407      46  \n",
       "18913     54  \n",
       "11081      8  \n",
       "...      ...  \n",
       "11284      2  \n",
       "11964     97  \n",
       "5390      40  \n",
       "860        1  \n",
       "15795     44  \n",
       "\n",
       "[15310 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "loudness            0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "valence             0\n",
       "popularity          0\n",
       "count               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (15310, 15) (15310,)\n",
      "Validation set shape: (5104, 15) (5104,)\n",
      "Test set shape: (5104, 15) (5104,)\n"
     ]
    }
   ],
   "source": [
    "artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "artists_encoded_test = artists_encoded_test.reset_index(drop=True)\n",
    "\n",
    "X_train_scaled[['Artists_encoded','key','mode']] = artists_encoded_train\n",
    "X_valid_scaled[['Artists_encoded','key','mode']] = artists_encoded_valid\n",
    "X_test_scaled[['Artists_encoded','key','mode']] = artists_encoded_test\n",
    "\n",
    "print(\"Training set shape:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_valid_scaled.shape, y_valid.shape)\n",
    "print(\"Test set shape:\", X_test_scaled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>count</th>\n",
       "      <th>Artists_encoded</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577992</td>\n",
       "      <td>0.686295</td>\n",
       "      <td>0.683235</td>\n",
       "      <td>-0.094437</td>\n",
       "      <td>-0.463518</td>\n",
       "      <td>1.355703</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.468020</td>\n",
       "      <td>0.133736</td>\n",
       "      <td>-0.018584</td>\n",
       "      <td>4093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.731851</td>\n",
       "      <td>0.362544</td>\n",
       "      <td>0.359663</td>\n",
       "      <td>0.688777</td>\n",
       "      <td>-0.462981</td>\n",
       "      <td>-1.227454</td>\n",
       "      <td>-0.280344</td>\n",
       "      <td>-0.642157</td>\n",
       "      <td>0.297761</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>-0.270294</td>\n",
       "      <td>-0.263442</td>\n",
       "      <td>795</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746930</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>-0.531952</td>\n",
       "      <td>-0.338965</td>\n",
       "      <td>-0.463529</td>\n",
       "      <td>-0.030058</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>-0.663310</td>\n",
       "      <td>0.555861</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.342532</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>2240</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814370</td>\n",
       "      <td>0.536825</td>\n",
       "      <td>-0.567066</td>\n",
       "      <td>0.594127</td>\n",
       "      <td>-0.462508</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.963548</td>\n",
       "      <td>0.206359</td>\n",
       "      <td>-0.226912</td>\n",
       "      <td>0.408453</td>\n",
       "      <td>1.367061</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>3886</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319500</td>\n",
       "      <td>-0.849226</td>\n",
       "      <td>0.234243</td>\n",
       "      <td>1.049463</td>\n",
       "      <td>0.692151</td>\n",
       "      <td>-0.327963</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>-0.569755</td>\n",
       "      <td>-0.467973</td>\n",
       "      <td>0.782811</td>\n",
       "      <td>-0.578607</td>\n",
       "      <td>-0.372267</td>\n",
       "      <td>777</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>2.014037</td>\n",
       "      <td>0.300867</td>\n",
       "      <td>0.341405</td>\n",
       "      <td>-1.417040</td>\n",
       "      <td>-0.463532</td>\n",
       "      <td>-1.181648</td>\n",
       "      <td>0.047263</td>\n",
       "      <td>-0.558145</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>-0.553695</td>\n",
       "      <td>0.843057</td>\n",
       "      <td>-0.453886</td>\n",
       "      <td>4718</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>-0.256262</td>\n",
       "      <td>1.197109</td>\n",
       "      <td>-0.196190</td>\n",
       "      <td>0.706854</td>\n",
       "      <td>-0.462485</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>1.056213</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.453433</td>\n",
       "      <td>0.644692</td>\n",
       "      <td>1.049305</td>\n",
       "      <td>0.838417</td>\n",
       "      <td>6250</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>1.440459</td>\n",
       "      <td>-1.964127</td>\n",
       "      <td>-1.228116</td>\n",
       "      <td>-1.385264</td>\n",
       "      <td>-0.460782</td>\n",
       "      <td>-0.333698</td>\n",
       "      <td>-0.787261</td>\n",
       "      <td>-0.643028</td>\n",
       "      <td>-0.419858</td>\n",
       "      <td>-0.824134</td>\n",
       "      <td>-1.565207</td>\n",
       "      <td>0.063035</td>\n",
       "      <td>3776</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>-0.668442</td>\n",
       "      <td>1.665016</td>\n",
       "      <td>0.894906</td>\n",
       "      <td>-0.884019</td>\n",
       "      <td>-0.455398</td>\n",
       "      <td>0.206987</td>\n",
       "      <td>-0.213386</td>\n",
       "      <td>2.982961</td>\n",
       "      <td>-1.743804</td>\n",
       "      <td>-0.515818</td>\n",
       "      <td>0.706029</td>\n",
       "      <td>-0.467489</td>\n",
       "      <td>6487</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>-0.118571</td>\n",
       "      <td>0.491670</td>\n",
       "      <td>0.585806</td>\n",
       "      <td>-0.520247</td>\n",
       "      <td>-0.463526</td>\n",
       "      <td>-0.392905</td>\n",
       "      <td>0.240399</td>\n",
       "      <td>-0.347139</td>\n",
       "      <td>-0.293170</td>\n",
       "      <td>-0.436744</td>\n",
       "      <td>-0.142609</td>\n",
       "      <td>0.117448</td>\n",
       "      <td>2425</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "0         -0.577992      0.686295     0.683235 -0.094437         -0.463518   \n",
       "1         -0.731851      0.362544     0.359663  0.688777         -0.462981   \n",
       "2          0.746930      0.360494    -0.531952 -0.338965         -0.463529   \n",
       "3         -0.814370      0.536825    -0.567066  0.594127         -0.462508   \n",
       "4          0.319500     -0.849226     0.234243  1.049463          0.692151   \n",
       "...             ...           ...          ...       ...               ...   \n",
       "15305      2.014037      0.300867     0.341405 -1.417040         -0.463532   \n",
       "15306     -0.256262      1.197109    -0.196190  0.706854         -0.462485   \n",
       "15307      1.440459     -1.964127    -1.228116 -1.385264         -0.460782   \n",
       "15308     -0.668442      1.665016     0.894906 -0.884019         -0.455398   \n",
       "15309     -0.118571      0.491670     0.585806 -0.520247         -0.463526   \n",
       "\n",
       "       liveness  loudness  speechiness     tempo   valence  popularity  \\\n",
       "0      1.355703 -0.612333    -0.006016  0.019832  0.468020    0.133736   \n",
       "1     -1.227454 -0.280344    -0.642157  0.297761  0.669181   -0.270294   \n",
       "2     -0.030058  0.166498    -0.663310  0.555861 -0.286911   -0.342532   \n",
       "3      0.021320  0.963548     0.206359 -0.226912  0.408453    1.367061   \n",
       "4     -0.327963  0.405750    -0.569755 -0.467973  0.782811   -0.578607   \n",
       "...         ...       ...          ...       ...       ...         ...   \n",
       "15305 -1.181648  0.047263    -0.558145 -0.028976 -0.553695    0.843057   \n",
       "15306 -0.206194  1.056213     0.153800  0.453433  0.644692    1.049305   \n",
       "15307 -0.333698 -0.787261    -0.643028 -0.419858 -0.824134   -1.565207   \n",
       "15308  0.206987 -0.213386     2.982961 -1.743804 -0.515818    0.706029   \n",
       "15309 -0.392905  0.240399    -0.347139 -0.293170 -0.436744   -0.142609   \n",
       "\n",
       "          count  Artists_encoded  key  mode  \n",
       "0     -0.018584             4093    5     0  \n",
       "1     -0.263442              795    4     1  \n",
       "2      0.144654             2240    4     1  \n",
       "3      0.253480             3886    0     1  \n",
       "4     -0.372267              777    7     1  \n",
       "...         ...              ...  ...   ...  \n",
       "15305 -0.453886             4718    4     1  \n",
       "15306  0.838417             6250    7     0  \n",
       "15307  0.063035             3776    7     1  \n",
       "15308 -0.467489             6487    5     0  \n",
       "15309  0.117448             2425    9     0  \n",
       "\n",
       "[15310 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "loudness            0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "valence             0\n",
       "popularity          0\n",
       "count               0\n",
       "Artists_encoded     0\n",
       "key                 0\n",
       "mode                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = X_train_scaled.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>count</th>\n",
       "      <th>Artists_encoded</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577992</td>\n",
       "      <td>0.686295</td>\n",
       "      <td>0.683235</td>\n",
       "      <td>-0.463518</td>\n",
       "      <td>1.355703</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.468020</td>\n",
       "      <td>0.133736</td>\n",
       "      <td>-0.018584</td>\n",
       "      <td>4093</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.731851</td>\n",
       "      <td>0.362544</td>\n",
       "      <td>0.359663</td>\n",
       "      <td>-0.462981</td>\n",
       "      <td>-1.227454</td>\n",
       "      <td>-0.642157</td>\n",
       "      <td>0.297761</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>-0.270294</td>\n",
       "      <td>-0.263442</td>\n",
       "      <td>795</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746930</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>-0.531952</td>\n",
       "      <td>-0.463529</td>\n",
       "      <td>-0.030058</td>\n",
       "      <td>-0.663310</td>\n",
       "      <td>0.555861</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.342532</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>2240</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814370</td>\n",
       "      <td>0.536825</td>\n",
       "      <td>-0.567066</td>\n",
       "      <td>-0.462508</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.206359</td>\n",
       "      <td>-0.226912</td>\n",
       "      <td>0.408453</td>\n",
       "      <td>1.367061</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>3886</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319500</td>\n",
       "      <td>-0.849226</td>\n",
       "      <td>0.234243</td>\n",
       "      <td>0.692151</td>\n",
       "      <td>-0.327963</td>\n",
       "      <td>-0.569755</td>\n",
       "      <td>-0.467973</td>\n",
       "      <td>0.782811</td>\n",
       "      <td>-0.578607</td>\n",
       "      <td>-0.372267</td>\n",
       "      <td>777</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>2.014037</td>\n",
       "      <td>0.300867</td>\n",
       "      <td>0.341405</td>\n",
       "      <td>-0.463532</td>\n",
       "      <td>-1.181648</td>\n",
       "      <td>-0.558145</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>-0.553695</td>\n",
       "      <td>0.843057</td>\n",
       "      <td>-0.453886</td>\n",
       "      <td>4718</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>-0.256262</td>\n",
       "      <td>1.197109</td>\n",
       "      <td>-0.196190</td>\n",
       "      <td>-0.462485</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.453433</td>\n",
       "      <td>0.644692</td>\n",
       "      <td>1.049305</td>\n",
       "      <td>0.838417</td>\n",
       "      <td>6250</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>1.440459</td>\n",
       "      <td>-1.964127</td>\n",
       "      <td>-1.228116</td>\n",
       "      <td>-0.460782</td>\n",
       "      <td>-0.333698</td>\n",
       "      <td>-0.643028</td>\n",
       "      <td>-0.419858</td>\n",
       "      <td>-0.824134</td>\n",
       "      <td>-1.565207</td>\n",
       "      <td>0.063035</td>\n",
       "      <td>3776</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>-0.668442</td>\n",
       "      <td>1.665016</td>\n",
       "      <td>0.894906</td>\n",
       "      <td>-0.455398</td>\n",
       "      <td>0.206987</td>\n",
       "      <td>2.982961</td>\n",
       "      <td>-1.743804</td>\n",
       "      <td>-0.515818</td>\n",
       "      <td>0.706029</td>\n",
       "      <td>-0.467489</td>\n",
       "      <td>6487</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>-0.118571</td>\n",
       "      <td>0.491670</td>\n",
       "      <td>0.585806</td>\n",
       "      <td>-0.463526</td>\n",
       "      <td>-0.392905</td>\n",
       "      <td>-0.347139</td>\n",
       "      <td>-0.293170</td>\n",
       "      <td>-0.436744</td>\n",
       "      <td>-0.142609</td>\n",
       "      <td>0.117448</td>\n",
       "      <td>2425</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability  duration_ms  instrumentalness  liveness  \\\n",
       "0         -0.577992      0.686295     0.683235         -0.463518  1.355703   \n",
       "1         -0.731851      0.362544     0.359663         -0.462981 -1.227454   \n",
       "2          0.746930      0.360494    -0.531952         -0.463529 -0.030058   \n",
       "3         -0.814370      0.536825    -0.567066         -0.462508  0.021320   \n",
       "4          0.319500     -0.849226     0.234243          0.692151 -0.327963   \n",
       "...             ...           ...          ...               ...       ...   \n",
       "15305      2.014037      0.300867     0.341405         -0.463532 -1.181648   \n",
       "15306     -0.256262      1.197109    -0.196190         -0.462485 -0.206194   \n",
       "15307      1.440459     -1.964127    -1.228116         -0.460782 -0.333698   \n",
       "15308     -0.668442      1.665016     0.894906         -0.455398  0.206987   \n",
       "15309     -0.118571      0.491670     0.585806         -0.463526 -0.392905   \n",
       "\n",
       "       speechiness     tempo   valence  popularity     count  Artists_encoded  \\\n",
       "0        -0.006016  0.019832  0.468020    0.133736 -0.018584             4093   \n",
       "1        -0.642157  0.297761  0.669181   -0.270294 -0.263442              795   \n",
       "2        -0.663310  0.555861 -0.286911   -0.342532  0.144654             2240   \n",
       "3         0.206359 -0.226912  0.408453    1.367061  0.253480             3886   \n",
       "4        -0.569755 -0.467973  0.782811   -0.578607 -0.372267              777   \n",
       "...            ...       ...       ...         ...       ...              ...   \n",
       "15305    -0.558145 -0.028976 -0.553695    0.843057 -0.453886             4718   \n",
       "15306     0.153800  0.453433  0.644692    1.049305  0.838417             6250   \n",
       "15307    -0.643028 -0.419858 -0.824134   -1.565207  0.063035             3776   \n",
       "15308     2.982961 -1.743804 -0.515818    0.706029 -0.467489             6487   \n",
       "15309    -0.347139 -0.293170 -0.436744   -0.142609  0.117448             2425   \n",
       "\n",
       "       key  mode  \n",
       "0        5     0  \n",
       "1        4     1  \n",
       "2        4     1  \n",
       "3        0     1  \n",
       "4        7     1  \n",
       "...    ...   ...  \n",
       "15305    4     1  \n",
       "15306    7     0  \n",
       "15307    7     1  \n",
       "15308    5     0  \n",
       "15309    9     0  \n",
       "\n",
       "[15310 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = X_train_scaled.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_selected = X_train_scaled.drop(columns=to_drop)\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features Selected by Random Forest:\n",
      "             Feature  Importance\n",
      "10        popularity    0.081620\n",
      "7        speechiness    0.080651\n",
      "0       acousticness    0.080325\n",
      "1       danceability    0.079380\n",
      "2        duration_ms    0.078937\n",
      "9            valence    0.074997\n",
      "3             energy    0.073388\n",
      "6           loudness    0.072826\n",
      "4   instrumentalness    0.069403\n",
      "8              tempo    0.066020\n",
      "12   Artists_encoded    0.064008\n",
      "5           liveness    0.063934\n",
      "11             count    0.058138\n",
      "13               key    0.044521\n",
      "14              mode    0.011851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train_scaled.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Top Features Selected by Random Forest:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled1 = X_train_scaled.drop(columns=['mode','energy'])\n",
    "X_valid_scaled1 = X_valid_scaled.drop(columns=['mode','energy'])\n",
    "X_test_scaled1 = X_test_scaled.drop(columns=['mode','energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>count</th>\n",
       "      <th>Artists_encoded</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577992</td>\n",
       "      <td>0.686295</td>\n",
       "      <td>0.683235</td>\n",
       "      <td>-0.463518</td>\n",
       "      <td>1.355703</td>\n",
       "      <td>-0.612333</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.468020</td>\n",
       "      <td>0.133736</td>\n",
       "      <td>-0.018584</td>\n",
       "      <td>4093</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.731851</td>\n",
       "      <td>0.362544</td>\n",
       "      <td>0.359663</td>\n",
       "      <td>-0.462981</td>\n",
       "      <td>-1.227454</td>\n",
       "      <td>-0.280344</td>\n",
       "      <td>-0.642157</td>\n",
       "      <td>0.297761</td>\n",
       "      <td>0.669181</td>\n",
       "      <td>-0.270294</td>\n",
       "      <td>-0.263442</td>\n",
       "      <td>795</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.746930</td>\n",
       "      <td>0.360494</td>\n",
       "      <td>-0.531952</td>\n",
       "      <td>-0.463529</td>\n",
       "      <td>-0.030058</td>\n",
       "      <td>0.166498</td>\n",
       "      <td>-0.663310</td>\n",
       "      <td>0.555861</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.342532</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>2240</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814370</td>\n",
       "      <td>0.536825</td>\n",
       "      <td>-0.567066</td>\n",
       "      <td>-0.462508</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.963548</td>\n",
       "      <td>0.206359</td>\n",
       "      <td>-0.226912</td>\n",
       "      <td>0.408453</td>\n",
       "      <td>1.367061</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>3886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319500</td>\n",
       "      <td>-0.849226</td>\n",
       "      <td>0.234243</td>\n",
       "      <td>0.692151</td>\n",
       "      <td>-0.327963</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>-0.569755</td>\n",
       "      <td>-0.467973</td>\n",
       "      <td>0.782811</td>\n",
       "      <td>-0.578607</td>\n",
       "      <td>-0.372267</td>\n",
       "      <td>777</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15305</th>\n",
       "      <td>2.014037</td>\n",
       "      <td>0.300867</td>\n",
       "      <td>0.341405</td>\n",
       "      <td>-0.463532</td>\n",
       "      <td>-1.181648</td>\n",
       "      <td>0.047263</td>\n",
       "      <td>-0.558145</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>-0.553695</td>\n",
       "      <td>0.843057</td>\n",
       "      <td>-0.453886</td>\n",
       "      <td>4718</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15306</th>\n",
       "      <td>-0.256262</td>\n",
       "      <td>1.197109</td>\n",
       "      <td>-0.196190</td>\n",
       "      <td>-0.462485</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>1.056213</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.453433</td>\n",
       "      <td>0.644692</td>\n",
       "      <td>1.049305</td>\n",
       "      <td>0.838417</td>\n",
       "      <td>6250</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15307</th>\n",
       "      <td>1.440459</td>\n",
       "      <td>-1.964127</td>\n",
       "      <td>-1.228116</td>\n",
       "      <td>-0.460782</td>\n",
       "      <td>-0.333698</td>\n",
       "      <td>-0.787261</td>\n",
       "      <td>-0.643028</td>\n",
       "      <td>-0.419858</td>\n",
       "      <td>-0.824134</td>\n",
       "      <td>-1.565207</td>\n",
       "      <td>0.063035</td>\n",
       "      <td>3776</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>-0.668442</td>\n",
       "      <td>1.665016</td>\n",
       "      <td>0.894906</td>\n",
       "      <td>-0.455398</td>\n",
       "      <td>0.206987</td>\n",
       "      <td>-0.213386</td>\n",
       "      <td>2.982961</td>\n",
       "      <td>-1.743804</td>\n",
       "      <td>-0.515818</td>\n",
       "      <td>0.706029</td>\n",
       "      <td>-0.467489</td>\n",
       "      <td>6487</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>-0.118571</td>\n",
       "      <td>0.491670</td>\n",
       "      <td>0.585806</td>\n",
       "      <td>-0.463526</td>\n",
       "      <td>-0.392905</td>\n",
       "      <td>0.240399</td>\n",
       "      <td>-0.347139</td>\n",
       "      <td>-0.293170</td>\n",
       "      <td>-0.436744</td>\n",
       "      <td>-0.142609</td>\n",
       "      <td>0.117448</td>\n",
       "      <td>2425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15310 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness  danceability  duration_ms  instrumentalness  liveness  \\\n",
       "0         -0.577992      0.686295     0.683235         -0.463518  1.355703   \n",
       "1         -0.731851      0.362544     0.359663         -0.462981 -1.227454   \n",
       "2          0.746930      0.360494    -0.531952         -0.463529 -0.030058   \n",
       "3         -0.814370      0.536825    -0.567066         -0.462508  0.021320   \n",
       "4          0.319500     -0.849226     0.234243          0.692151 -0.327963   \n",
       "...             ...           ...          ...               ...       ...   \n",
       "15305      2.014037      0.300867     0.341405         -0.463532 -1.181648   \n",
       "15306     -0.256262      1.197109    -0.196190         -0.462485 -0.206194   \n",
       "15307      1.440459     -1.964127    -1.228116         -0.460782 -0.333698   \n",
       "15308     -0.668442      1.665016     0.894906         -0.455398  0.206987   \n",
       "15309     -0.118571      0.491670     0.585806         -0.463526 -0.392905   \n",
       "\n",
       "       loudness  speechiness     tempo   valence  popularity     count  \\\n",
       "0     -0.612333    -0.006016  0.019832  0.468020    0.133736 -0.018584   \n",
       "1     -0.280344    -0.642157  0.297761  0.669181   -0.270294 -0.263442   \n",
       "2      0.166498    -0.663310  0.555861 -0.286911   -0.342532  0.144654   \n",
       "3      0.963548     0.206359 -0.226912  0.408453    1.367061  0.253480   \n",
       "4      0.405750    -0.569755 -0.467973  0.782811   -0.578607 -0.372267   \n",
       "...         ...          ...       ...       ...         ...       ...   \n",
       "15305  0.047263    -0.558145 -0.028976 -0.553695    0.843057 -0.453886   \n",
       "15306  1.056213     0.153800  0.453433  0.644692    1.049305  0.838417   \n",
       "15307 -0.787261    -0.643028 -0.419858 -0.824134   -1.565207  0.063035   \n",
       "15308 -0.213386     2.982961 -1.743804 -0.515818    0.706029 -0.467489   \n",
       "15309  0.240399    -0.347139 -0.293170 -0.436744   -0.142609  0.117448   \n",
       "\n",
       "       Artists_encoded  key  \n",
       "0                 4093    5  \n",
       "1                  795    4  \n",
       "2                 2240    4  \n",
       "3                 3886    0  \n",
       "4                  777    7  \n",
       "...                ...  ...  \n",
       "15305             4718    4  \n",
       "15306             6250    7  \n",
       "15307             3776    7  \n",
       "15308             6487    5  \n",
       "15309             2425    9  \n",
       "\n",
       "[15310 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neo soul', 'new romantic', 'country road', 'pop', 'indie pop',\n",
       "       'alternative metal', 'electronica', 'rap', 'electropop',\n",
       "       'pop rock', 'brill building pop', 'big band', 'funk', 'classical',\n",
       "       'show tunes', 'soft rock', 'folk rock', 'rock', 'dance pop',\n",
       "       'new wave pop', 'country rock', 'southern hip hop', 'hard rock',\n",
       "       'hip hop', 'ccm', 'hollywood', 'lounge', 'neo mellow',\n",
       "       'stomp and holler', 'punk', 'nuevo regional mexicano', 'pop rap',\n",
       "       'hardcore hip hop', 'underground hip hop', 'alternative rock',\n",
       "       'motown', 'bebop', 'soul', 'regional mexican', 'adult standards',\n",
       "       'pop punk', 'bubblegum pop', 'edm', 'disco', 'new americana',\n",
       "       'latin pop', 'indie folk', 'trap latino', 'tropical', 'folk',\n",
       "       'alternative hip hop', 'jazz', 'modern rock',\n",
       "       'contemporary post-bop', 'urban contemporary', 'traditional folk',\n",
       "       'country', 'filmi', 'hip pop', 'classic rock', 'pop dance',\n",
       "       'mellow gold', 'classical performance', 'contemporary country',\n",
       "       'r&b', 'blues rock', 'dance rock', 'classic uk pop',\n",
       "       'classic soul', 'tropical house', 'post-teen pop', 'indie rock',\n",
       "       'corrido', 'movie tunes', 'electro house', 'hard bop', 'trap',\n",
       "       'latin hip hop', 'psychedelic rock', 'roots rock', 'latin',\n",
       "       'nu metal', 'metal', 'indie poptimism', 'cool jazz',\n",
       "       'gangster rap', 'dirty south rap', 'art rock', 'soul jazz',\n",
       "       'vocal jazz', 'reggaeton', 'post-disco', 'new wave',\n",
       "       'rock-and-roll', 'modern alternative rock', 'jazz funk',\n",
       "       'new jack swing', 'quiet storm', 'album rock', 'rock en espanol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=3: Additional Validation Set: 0.02\n",
      "Accuracy for k=3: Additional Test Set: 0.01\n",
      "Accuracy for k=5: Additional Validation Set: 0.02\n",
      "Accuracy for k=5: Additional Test Set: 0.01\n",
      "Accuracy for k=7: Additional Validation Set: 0.02\n",
      "Accuracy for k=7: Additional Test Set: 0.01\n",
      "Accuracy for k=9: Additional Validation Set: 0.02\n",
      "Accuracy for k=9: Additional Test Set: 0.01\n",
      "Accuracy for k=11: Additional Validation Set: 0.02\n",
      "Accuracy for k=11: Additional Test Set: 0.01\n",
      "Accuracy for k=13: Additional Validation Set: 0.03\n",
      "Accuracy for k=13: Additional Test Set: 0.01\n",
      "Accuracy for k=15: Additional Validation Set: 0.03\n",
      "Accuracy for k=15: Additional Test Set: 0.01\n",
      "Accuracy for k=17: Additional Validation Set: 0.03\n",
      "Accuracy for k=17: Additional Test Set: 0.01\n",
      "Accuracy for k=19: Additional Validation Set: 0.03\n",
      "Accuracy for k=19: Additional Test Set: 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
    "\n",
    "k_values = [3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "\n",
    "for k in k_values:\n",
    "    # Initialize the KNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    knn_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "\n",
    "    # Make predictions on the additional validation set\n",
    "    y_pred_val1 = knn_classifier.predict(X_valid_scaled1)\n",
    "    accuracy_val1 = accuracy_score(y_valid, y_pred_val1)\n",
    "    \n",
    "    y_pred_test1 = knn_classifier.predict(X_test_scaled1)\n",
    "    accuracy_test1 = accuracy_score(y_test, y_pred_val1)\n",
    "    \n",
    "\n",
    "    # Print the performance for each k on both test and additional validation sets\n",
    "    print(f'Accuracy for k={k}: Additional Validation Set: {accuracy_val1:.2f}')\n",
    "    print(f'Accuracy for k={k}: Additional Test Set: {accuracy_test1:.2f}')\n",
    "    '''print('\\nClassification Report:')\n",
    "    print(classification_report(y_valid, y_pred_val1))\n",
    "    print('\\n---------------------------\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.06\n",
      "Accuracy on Test Set: 0.00\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        69\n",
      "           1       0.00      0.00      0.00        63\n",
      "           2       0.00      0.00      0.00        41\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       0.00      0.00      0.00        61\n",
      "           5       0.00      0.00      0.00        46\n",
      "           6       0.08      0.18      0.11        28\n",
      "           7       0.03      0.10      0.04        20\n",
      "           8       0.00      0.00      0.00        33\n",
      "           9       0.00      0.00      0.00        34\n",
      "          10       0.00      0.00      0.00        24\n",
      "          11       0.00      0.00      0.00        20\n",
      "          12       0.00      0.00      0.00        47\n",
      "          13       0.00      0.00      0.00        41\n",
      "          14       0.00      0.00      0.00        30\n",
      "          15       0.23      0.88      0.36        33\n",
      "          16       0.00      0.00      0.00        41\n",
      "          17       0.00      0.00      0.00        41\n",
      "          18       0.33      0.04      0.08        23\n",
      "          19       0.07      0.06      0.07        31\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.00      0.00      0.00        51\n",
      "          22       0.00      0.00      0.00        31\n",
      "          23       0.00      0.00      0.00        66\n",
      "          24       0.00      0.00      0.00        96\n",
      "          25       0.00      0.00      0.00        35\n",
      "          26       0.00      0.00      0.00        23\n",
      "          27       0.00      0.00      0.00        35\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00        20\n",
      "          30       0.00      0.00      0.00        34\n",
      "          31       0.00      0.00      0.00        39\n",
      "          32       0.00      0.00      0.00        17\n",
      "          33       0.00      0.00      0.00        26\n",
      "          34       0.00      0.00      0.00        59\n",
      "          35       0.07      0.41      0.12        66\n",
      "          36       0.17      0.02      0.03        54\n",
      "          37       0.00      0.00      0.00        22\n",
      "          38       0.00      0.00      0.00        43\n",
      "          39       0.03      0.07      0.05        28\n",
      "          40       0.08      0.63      0.14        65\n",
      "          41       0.00      0.00      0.00        41\n",
      "          42       0.00      0.00      0.00        29\n",
      "          43       0.07      0.12      0.09        32\n",
      "          44       0.00      0.00      0.00        40\n",
      "          45       0.00      0.00      0.00        25\n",
      "          46       0.00      0.00      0.00        50\n",
      "          47       0.18      0.35      0.23        37\n",
      "          48       0.00      0.00      0.00        31\n",
      "          49       0.00      0.00      0.00        64\n",
      "          50       0.00      0.00      0.00        26\n",
      "          51       0.00      0.00      0.00        32\n",
      "          52       0.00      0.00      0.00        30\n",
      "          53       0.00      0.00      0.00        70\n",
      "          54       0.00      0.00      0.00        28\n",
      "          55       0.00      0.00      0.00        25\n",
      "          56       0.00      0.00      0.00        72\n",
      "          57       0.00      0.00      0.00        32\n",
      "          58       0.11      0.15      0.13        27\n",
      "          59       0.00      0.00      0.00        19\n",
      "          60       0.00      0.00      0.00        20\n",
      "          61       0.00      0.00      0.00        26\n",
      "          62       0.00      0.00      0.00        23\n",
      "          63       0.00      0.00      0.00        22\n",
      "          64       0.00      0.00      0.00        25\n",
      "          65       0.00      0.00      0.00        55\n",
      "          66       0.00      0.00      0.00        35\n",
      "          67       0.00      0.00      0.00        25\n",
      "          68       0.05      0.55      0.08        93\n",
      "          69       0.00      0.00      0.00        45\n",
      "          70       0.00      0.00      0.00        32\n",
      "          71       0.00      0.00      0.00        77\n",
      "          72       0.00      0.00      0.00        52\n",
      "          73       0.00      0.00      0.00        32\n",
      "          74       0.00      0.00      0.00        58\n",
      "          75       0.00      0.00      0.00        35\n",
      "          76       0.00      0.00      0.00        34\n",
      "          77       0.00      0.00      0.00        44\n",
      "          78       0.00      0.00      0.00        48\n",
      "          79       0.05      0.02      0.03        91\n",
      "          80       0.00      0.00      0.00        28\n",
      "          81       0.00      0.00      0.00        57\n",
      "          82       0.06      0.75      0.11        95\n",
      "          83       0.00      0.00      0.00        31\n",
      "          84       0.00      0.00      0.00        30\n",
      "          85       0.00      0.00      0.00        49\n",
      "          86       0.22      0.08      0.12        24\n",
      "          87       0.00      0.00      0.00        55\n",
      "          88       0.00      0.00      0.00        40\n",
      "          89       0.03      0.04      0.03        28\n",
      "          90       0.00      0.00      0.00        62\n",
      "          91       0.00      0.00      0.00        33\n",
      "          92       0.00      0.00      0.00        28\n",
      "          93       0.00      0.00      0.00        59\n",
      "          94       0.00      0.00      0.00        25\n",
      "          95       0.00      0.00      0.00        42\n",
      "          96       0.00      0.00      0.00        26\n",
      "          97       0.00      0.00      0.00        32\n",
      "          98       0.00      0.00      0.00        60\n",
      "          99       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.06      4083\n",
      "   macro avg       0.02      0.04      0.02      4083\n",
      "weighted avg       0.02      0.06      0.02      4083\n",
      "\n",
      "\n",
      "Classification Report on Test Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1161ac7ee08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nClassification Report on Test Set:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "adaboost_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_valid = adaboost_classifier.predict(X_valid_scaled1)\n",
    "y_pred_test = adaboost_classifier.predict(X_test_scaled1)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "print(f'Accuracy on Validation Set: {accuracy_valid:.2f}')\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy on Test Set: {accuracy_test:.2f}')\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print('\\nClassification Report on Validation Set:')\n",
    "print(classification_report(y_valid, y_pred_valid))\n",
    "\n",
    "print('\\nClassification Report on Test Set:')\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy using Naive Bayes: 0.11\n",
      "Test Accuracy using Naive Bayes: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "train_df['target'] = train_df['genres'].astype('category').cat.codes\n",
    "\n",
    "# Extract features and target variable\n",
    "X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "y = train_df['target']  # Numeric target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "artists_encoded_train = X_train[['Artists_encoded', 'key', 'mode']]\n",
    "artists_encoded_valid = X_valid[['Artists_encoded', 'key', 'mode']]\n",
    "X_train = X_train.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "X_valid = X_valid.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "X_train_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_train\n",
    "X_valid_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_valid\n",
    "\n",
    "X_train_scaled1 = X_train_scaled.drop(columns=['mode', 'energy'])\n",
    "X_valid_scaled1 = X_valid_scaled.drop(columns=['mode', 'energy'])\n",
    "\n",
    "# Check if the data is textual or numerical\n",
    "is_text_data = isinstance(X_train_scaled1.iloc[0, 0], str)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "if is_text_data:\n",
    "    naive_bayes_classifier = OneVsOneClassifier(MultinomialNB())\n",
    "else:\n",
    "    naive_bayes_classifier = OneVsOneClassifier(GaussianNB())\n",
    "\n",
    "# Train the classifier on the training set\n",
    "naive_bayes_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_valid = naive_bayes_classifier.predict(X_valid_scaled1)\n",
    "y_pred_test = naive_bayes_classifier.predict(X_test_scaled1)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "print(f'Validation Accuracy using Naive Bayes: {accuracy_valid:.2f}')\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Test Accuracy using Naive Bayes: {accuracy_test:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for dance rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for classic rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for dance pop: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for pop punk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for modern alternative rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for traditional folk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for roots rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for pop: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for indie rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for country road: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hip hop: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for southern hip hop: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for adult standards: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for pop rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for album rock: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for nu metal: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for dirty south rap: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for electro house: 1.00, Test Accuracy: 0.00 \n",
      "Validation Accuracy for cool jazz: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for brill building pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for trap: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for disco: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hip pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for alternative rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for corrido: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for rock: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for latin hip hop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for edm: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for art rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for tropical: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for r&b: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for country rock: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for ccm: 1.00, Test Accuracy: 0.00 \n",
      "Validation Accuracy for classic uk pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for latin: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for movie tunes: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hard rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for jazz: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for blues rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for gangster rap: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for pop dance: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for underground hip hop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for electronica: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for psychedelic rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for soul jazz: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for show tunes: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for new americana: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for folk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for electropop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for urban contemporary: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for bebop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for alternative metal: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for folk rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for modern rock: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for contemporary post-bop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hard bop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for indie folk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for post-teen pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for quiet storm: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for country: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hollywood: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for pop rap: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for tropical house: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for soul: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for classic soul: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for filmi: 1.00, Test Accuracy: 0.00 \n",
      "Validation Accuracy for neo soul: 1.00, Test Accuracy: 0.00 \n",
      "Validation Accuracy for lounge: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for rap: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for jazz funk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for indie pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for metal: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for motown: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for regional mexican: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for funk: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for classical: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for classical performance: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for indie poptimism: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for mellow gold: 0.98, Test Accuracy: 0.00 \n",
      "Validation Accuracy for vocal jazz: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for rock en espanol: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for stomp and holler: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for hardcore hip hop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for new romantic: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for latin pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for reggaeton: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for new wave pop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for post-disco: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for soft rock: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for trap latino: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for new wave: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for punk: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for neo mellow: 1.00, Test Accuracy: 0.00 \n",
      "Validation Accuracy for contemporary country: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for alternative hip hop: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for nuevo regional mexicano: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for big band: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for new jack swing: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for rock-and-roll: 0.99, Test Accuracy: 0.00 \n",
      "Validation Accuracy for bubblegum pop: 0.99, Test Accuracy: 0.00 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = train_df.drop(columns=['genres'])  # Features\n",
    "\n",
    "# Iterate over all unique genres\n",
    "for genre_of_interest in train_df['genres'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    train_df['target'] = (train_df['genres'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "    y = train_df['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    artists_encoded_train = X_train[['Artists_encoded','key','mode']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded','key','mode']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded','key','mode'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded','key','mode'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded','key','mode']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded','key','mode']] = artists_encoded_valid\n",
    "    \n",
    "    X_train_scaled1 = X_train_scaled.drop(columns=['mode','energy'])\n",
    "    X_valid_scaled1 = X_valid_scaled.drop(columns=['mode','energy'])\n",
    "    # Initialize the KNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Adjust k as needed\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    knn_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_valid = knn_classifier.predict(X_valid_scaled1)\n",
    "    y_pred_test = knn_classifier.predict(X_test_scaled1)\n",
    "\n",
    "    # Evaluate the performance on the test set\n",
    "    accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    \n",
    "    print(f'Validation Accuracy for {genre_of_interest}: {accuracy_valid:.2f}, Test Accuracy: {accuracy_test:.2f} ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dance rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for classic rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for dance pop using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for pop punk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for modern alternative rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for traditional folk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for roots rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for pop using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for indie rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for country road using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hip hop using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for southern hip hop using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for adult standards using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for pop rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for album rock using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for nu metal using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for dirty south rap using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for electro house using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for cool jazz using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for brill building pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for trap using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for disco using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hip pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for alternative rock using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for corrido using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for rock using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for latin hip hop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for edm using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for art rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for tropical using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for r&b using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for country rock using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for ccm using AdaBoost: 1.00,Test Accuracy: 0.00 \n",
      "Accuracy for classic uk pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for latin using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for movie tunes using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hard rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for jazz using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for blues rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for gangster rap using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for pop dance using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for underground hip hop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for electronica using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for psychedelic rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for soul jazz using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for show tunes using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for new americana using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for folk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for electropop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for urban contemporary using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for bebop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for alternative metal using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for folk rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for modern rock using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for contemporary post-bop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hard bop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for indie folk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for post-teen pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for quiet storm using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for country using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hollywood using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for pop rap using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for tropical house using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for soul using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for classic soul using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for filmi using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for neo soul using AdaBoost: 1.00,Test Accuracy: 0.00 \n",
      "Accuracy for lounge using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for rap using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for jazz funk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for indie pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for metal using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for motown using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for regional mexican using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for funk using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for classical using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for classical performance using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for indie poptimism using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for mellow gold using AdaBoost: 0.98,Test Accuracy: 0.00 \n",
      "Accuracy for vocal jazz using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for rock en espanol using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for stomp and holler using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for hardcore hip hop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for new romantic using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for latin pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for reggaeton using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for new wave pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for post-disco using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for soft rock using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for trap latino using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for new wave using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for punk using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for neo mellow using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for contemporary country using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for alternative hip hop using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for nuevo regional mexicano using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for big band using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for new jack swing using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for rock-and-roll using AdaBoost: 0.99,Test Accuracy: 0.00 \n",
      "Accuracy for bubblegum pop using AdaBoost: 0.99,Test Accuracy: 0.00 \n"
     ]
    }
   ],
   "source": [
    "for genre_of_interest in train_df['genres'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    train_df['target'] = (train_df['genres'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "    y = train_df['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    artists_encoded_train = X_train[['Artists_encoded', 'key', 'mode']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded', 'key', 'mode']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_valid\n",
    "\n",
    "    X_train_scaled1 = X_train_scaled.drop(columns=['mode', 'energy'])\n",
    "    X_valid_scaled1 = X_valid_scaled.drop(columns=['mode', 'energy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the AdaBoost classifier with a base estimator (you can change the base estimator as needed)\n",
    "    #base_estimator = KNeighborsClassifier(n_neighbors=5)  # Adjust k as needed\n",
    "    adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "    # Train the AdaBoost classifier on the training set\n",
    "    adaboost_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_valid = adaboost_classifier.predict(X_valid_scaled1)\n",
    "    y_pred_test = adaboost_classifier.predict(X_test_scaled1)\n",
    "    \n",
    "    # Evaluate the performance on the test set\n",
    "    accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(f'Accuracy for {genre_of_interest} using AdaBoost: {accuracy_valid:.2f},Test Accuracy: {accuracy_test:.2f} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for dance rock using AdaBoost: 0.00\n",
      "Best hyperparameters for dance rock: {'learning_rate': 1.0, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for classic rock using AdaBoost: 0.00\n",
      "Best hyperparameters for classic rock: {'learning_rate': 1.0, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7fcd8a1170a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Train the AdaBoost classifier on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \"\"\"\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \"\"\"\n\u001b[1;32m    904\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;34m\"\"\"Like assert_all_finite, but only for ndarray.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# validation is also imported in extmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have 'train_df' DataFrame with features and 'genres' as the target variable\n",
    "\n",
    "# Iterate over all unique genres\n",
    "for genre_of_interest in train_df['genres'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    train_df['target'] = (train_df['genres'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "    y = train_df['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    artists_encoded_train = X_train[['Artists_encoded', 'key', 'mode']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded', 'key', 'mode']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_valid\n",
    "\n",
    "    X_train_scaled1 = X_train_scaled.drop(columns=['mode', 'energy'])\n",
    "    X_valid_scaled1 = X_valid_scaled.drop(columns=['mode', 'energy'])\n",
    "\n",
    "    # Initialize the AdaBoost classifier\n",
    "    param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5, 1.0]}\n",
    "    adaboost_classifier = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, scoring='precision', cv=5)\n",
    "\n",
    "    # Train the AdaBoost classifier on the training set\n",
    "    adaboost_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = adaboost_classifier.predict(X_valid_scaled1)\n",
    "\n",
    "    # Evaluate the precision on the test set\n",
    "    precision_test = precision_score(y_valid, y_pred_test)\n",
    "    print(f'Precision for {genre_of_interest} using AdaBoost: {precision_test:.2f}')\n",
    "    \n",
    "    # Print the best hyperparameters found during grid search\n",
    "    print(f'Best hyperparameters for {genre_of_interest}: {adaboost_classifier.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dance rock using Naive Bayes: 0.99 \n",
      "Precision for dance rock using Naive Bayes: 0.00 \n",
      "Accuracy for classic rock using Naive Bayes: 0.97 \n",
      "Precision for classic rock using Naive Bayes: 0.07 \n",
      "Accuracy for dance pop using Naive Bayes: 0.87 \n",
      "Precision for dance pop using Naive Bayes: 0.10 \n",
      "Accuracy for pop punk using Naive Bayes: 0.97 \n",
      "Precision for pop punk using Naive Bayes: 0.09 \n",
      "Accuracy for modern alternative rock using Naive Bayes: 0.96 \n",
      "Precision for modern alternative rock using Naive Bayes: 0.01 \n",
      "Accuracy for traditional folk using Naive Bayes: 0.97 \n",
      "Precision for traditional folk using Naive Bayes: 0.09 \n",
      "Accuracy for roots rock using Naive Bayes: 0.98 \n",
      "Precision for roots rock using Naive Bayes: 0.04 \n",
      "Accuracy for pop using Naive Bayes: 0.91 \n",
      "Precision for pop using Naive Bayes: 0.12 \n",
      "Accuracy for indie rock using Naive Bayes: 0.97 \n",
      "Precision for indie rock using Naive Bayes: 0.08 \n",
      "Accuracy for country road using Naive Bayes: 0.93 \n",
      "Precision for country road using Naive Bayes: 0.06 \n",
      "Accuracy for hip hop using Naive Bayes: 0.90 \n",
      "Precision for hip hop using Naive Bayes: 0.09 \n",
      "Accuracy for southern hip hop using Naive Bayes: 0.91 \n",
      "Precision for southern hip hop using Naive Bayes: 0.10 \n",
      "Accuracy for adult standards using Naive Bayes: 0.95 \n",
      "Precision for adult standards using Naive Bayes: 0.17 \n",
      "Accuracy for pop rock using Naive Bayes: 0.96 \n",
      "Precision for pop rock using Naive Bayes: 0.05 \n",
      "Accuracy for album rock using Naive Bayes: 0.97 \n",
      "Precision for album rock using Naive Bayes: 0.16 \n",
      "Accuracy for nu metal using Naive Bayes: 0.97 \n",
      "Precision for nu metal using Naive Bayes: 0.12 \n",
      "Accuracy for dirty south rap using Naive Bayes: 0.88 \n",
      "Precision for dirty south rap using Naive Bayes: 0.03 \n",
      "Accuracy for electro house using Naive Bayes: 0.94 \n",
      "Precision for electro house using Naive Bayes: 0.05 \n",
      "Accuracy for cool jazz using Naive Bayes: 0.93 \n",
      "Precision for cool jazz using Naive Bayes: 0.08 \n",
      "Accuracy for brill building pop using Naive Bayes: 0.97 \n",
      "Precision for brill building pop using Naive Bayes: 0.12 \n",
      "Accuracy for trap using Naive Bayes: 0.88 \n",
      "Precision for trap using Naive Bayes: 0.08 \n",
      "Accuracy for disco using Naive Bayes: 0.97 \n",
      "Precision for disco using Naive Bayes: 0.08 \n",
      "Accuracy for hip pop using Naive Bayes: 0.84 \n",
      "Precision for hip pop using Naive Bayes: 0.04 \n",
      "Accuracy for alternative rock using Naive Bayes: 0.98 \n",
      "Precision for alternative rock using Naive Bayes: 0.13 \n",
      "Accuracy for corrido using Naive Bayes: 0.94 \n",
      "Precision for corrido using Naive Bayes: 0.10 \n",
      "Accuracy for rock using Naive Bayes: 0.96 \n",
      "Precision for rock using Naive Bayes: 0.14 \n",
      "Accuracy for latin hip hop using Naive Bayes: 0.95 \n",
      "Precision for latin hip hop using Naive Bayes: 0.01 \n",
      "Accuracy for edm using Naive Bayes: 0.95 \n",
      "Precision for edm using Naive Bayes: 0.11 \n",
      "Accuracy for art rock using Naive Bayes: 0.96 \n",
      "Precision for art rock using Naive Bayes: 0.04 \n",
      "Accuracy for tropical using Naive Bayes: 0.97 \n",
      "Precision for tropical using Naive Bayes: 0.12 \n",
      "Accuracy for r&b using Naive Bayes: 0.90 \n",
      "Precision for r&b using Naive Bayes: 0.04 \n",
      "Accuracy for country rock using Naive Bayes: 0.98 \n",
      "Precision for country rock using Naive Bayes: 0.05 \n",
      "Accuracy for ccm using Naive Bayes: 0.96 \n",
      "Precision for ccm using Naive Bayes: 0.04 \n",
      "Accuracy for classic uk pop using Naive Bayes: 0.99 \n",
      "Precision for classic uk pop using Naive Bayes: 0.00 \n",
      "Accuracy for latin using Naive Bayes: 0.96 \n",
      "Precision for latin using Naive Bayes: 0.12 \n",
      "Accuracy for movie tunes using Naive Bayes: 0.97 \n",
      "Precision for movie tunes using Naive Bayes: 0.12 \n",
      "Accuracy for hard rock using Naive Bayes: 0.98 \n",
      "Precision for hard rock using Naive Bayes: 0.13 \n",
      "Accuracy for jazz using Naive Bayes: 0.93 \n",
      "Precision for jazz using Naive Bayes: 0.09 \n",
      "Accuracy for blues rock using Naive Bayes: 0.98 \n",
      "Precision for blues rock using Naive Bayes: 0.03 \n",
      "Accuracy for gangster rap using Naive Bayes: 0.91 \n",
      "Precision for gangster rap using Naive Bayes: 0.11 \n",
      "Accuracy for pop dance using Naive Bayes: 0.95 \n",
      "Precision for pop dance using Naive Bayes: 0.09 \n",
      "Accuracy for underground hip hop using Naive Bayes: 0.94 \n",
      "Precision for underground hip hop using Naive Bayes: 0.05 \n",
      "Accuracy for electronica using Naive Bayes: 0.96 \n",
      "Precision for electronica using Naive Bayes: 0.09 \n",
      "Accuracy for psychedelic rock using Naive Bayes: 0.98 \n",
      "Precision for psychedelic rock using Naive Bayes: 0.04 \n",
      "Accuracy for soul jazz using Naive Bayes: 0.94 \n",
      "Precision for soul jazz using Naive Bayes: 0.08 \n",
      "Accuracy for show tunes using Naive Bayes: 0.97 \n",
      "Precision for show tunes using Naive Bayes: 0.10 \n",
      "Accuracy for new americana using Naive Bayes: 0.98 \n",
      "Precision for new americana using Naive Bayes: 0.07 \n",
      "Accuracy for folk using Naive Bayes: 0.97 \n",
      "Precision for folk using Naive Bayes: 0.03 \n",
      "Accuracy for electropop using Naive Bayes: 0.92 \n",
      "Precision for electropop using Naive Bayes: 0.04 \n",
      "Accuracy for urban contemporary using Naive Bayes: 0.95 \n",
      "Precision for urban contemporary using Naive Bayes: 0.07 \n",
      "Accuracy for bebop using Naive Bayes: 0.93 \n",
      "Precision for bebop using Naive Bayes: 0.07 \n",
      "Accuracy for alternative metal using Naive Bayes: 0.97 \n",
      "Precision for alternative metal using Naive Bayes: 0.19 \n",
      "Accuracy for folk rock using Naive Bayes: 0.96 \n",
      "Precision for folk rock using Naive Bayes: 0.09 \n",
      "Accuracy for modern rock using Naive Bayes: 0.94 \n",
      "Precision for modern rock using Naive Bayes: 0.08 \n",
      "Accuracy for contemporary post-bop using Naive Bayes: 0.93 \n",
      "Precision for contemporary post-bop using Naive Bayes: 0.06 \n",
      "Accuracy for hard bop using Naive Bayes: 0.94 \n",
      "Precision for hard bop using Naive Bayes: 0.07 \n",
      "Accuracy for indie folk using Naive Bayes: 0.97 \n",
      "Precision for indie folk using Naive Bayes: 0.08 \n",
      "Accuracy for post-teen pop using Naive Bayes: 0.86 \n",
      "Precision for post-teen pop using Naive Bayes: 0.06 \n",
      "Accuracy for quiet storm using Naive Bayes: 0.98 \n",
      "Precision for quiet storm using Naive Bayes: 0.15 \n",
      "Accuracy for country using Naive Bayes: 0.99 \n",
      "Precision for country using Naive Bayes: 0.00 \n",
      "Accuracy for hollywood using Naive Bayes: 0.99 \n",
      "Precision for hollywood using Naive Bayes: 0.03 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop rap using Naive Bayes: 0.89 \n",
      "Precision for pop rap using Naive Bayes: 0.08 \n",
      "Accuracy for tropical house using Naive Bayes: 0.95 \n",
      "Precision for tropical house using Naive Bayes: 0.05 \n",
      "Accuracy for soul using Naive Bayes: 0.99 \n",
      "Precision for soul using Naive Bayes: 0.08 \n",
      "Accuracy for classic soul using Naive Bayes: 0.99 \n",
      "Precision for classic soul using Naive Bayes: 0.00 \n",
      "Accuracy for filmi using Naive Bayes: 0.96 \n",
      "Precision for filmi using Naive Bayes: 0.02 \n",
      "Accuracy for neo soul using Naive Bayes: 0.92 \n",
      "Precision for neo soul using Naive Bayes: 0.02 \n",
      "Accuracy for lounge using Naive Bayes: 0.92 \n",
      "Precision for lounge using Naive Bayes: 0.04 \n",
      "Accuracy for rap using Naive Bayes: 0.89 \n",
      "Precision for rap using Naive Bayes: 0.13 \n",
      "Accuracy for jazz funk using Naive Bayes: 0.97 \n",
      "Precision for jazz funk using Naive Bayes: 0.10 \n",
      "Accuracy for indie pop using Naive Bayes: 0.98 \n",
      "Precision for indie pop using Naive Bayes: 0.04 \n",
      "Accuracy for metal using Naive Bayes: 0.98 \n",
      "Precision for metal using Naive Bayes: 0.22 \n",
      "Accuracy for motown using Naive Bayes: 0.99 \n",
      "Precision for motown using Naive Bayes: 0.00 \n",
      "Accuracy for regional mexican using Naive Bayes: 0.95 \n",
      "Precision for regional mexican using Naive Bayes: 0.16 \n",
      "Accuracy for funk using Naive Bayes: 0.98 \n",
      "Precision for funk using Naive Bayes: 0.00 \n",
      "Accuracy for classical using Naive Bayes: 0.96 \n",
      "Precision for classical using Naive Bayes: 0.17 \n",
      "Accuracy for classical performance using Naive Bayes: 0.96 \n",
      "Precision for classical performance using Naive Bayes: 0.18 \n",
      "Accuracy for indie poptimism using Naive Bayes: 0.86 \n",
      "Precision for indie poptimism using Naive Bayes: 0.03 \n",
      "Accuracy for mellow gold using Naive Bayes: 0.95 \n",
      "Precision for mellow gold using Naive Bayes: 0.07 \n",
      "Accuracy for vocal jazz using Naive Bayes: 0.93 \n",
      "Precision for vocal jazz using Naive Bayes: 0.05 \n",
      "Accuracy for rock en espanol using Naive Bayes: 0.99 \n",
      "Precision for rock en espanol using Naive Bayes: 0.11 \n",
      "Accuracy for stomp and holler using Naive Bayes: 0.97 \n",
      "Precision for stomp and holler using Naive Bayes: 0.04 \n",
      "Accuracy for hardcore hip hop using Naive Bayes: 0.93 \n",
      "Precision for hardcore hip hop using Naive Bayes: 0.08 \n",
      "Accuracy for new romantic using Naive Bayes: 0.99 \n",
      "Precision for new romantic using Naive Bayes: 0.19 \n",
      "Accuracy for latin pop using Naive Bayes: 0.99 \n",
      "Precision for latin pop using Naive Bayes: 0.00 \n",
      "Accuracy for reggaeton using Naive Bayes: 0.97 \n",
      "Precision for reggaeton using Naive Bayes: 0.10 \n",
      "Accuracy for new wave pop using Naive Bayes: 0.97 \n",
      "Precision for new wave pop using Naive Bayes: 0.05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for post-disco using Naive Bayes: 0.97 \n",
      "Precision for post-disco using Naive Bayes: 0.16 \n",
      "Accuracy for soft rock using Naive Bayes: 0.95 \n",
      "Precision for soft rock using Naive Bayes: 0.07 \n",
      "Accuracy for trap latino using Naive Bayes: 0.98 \n",
      "Precision for trap latino using Naive Bayes: 0.08 \n",
      "Accuracy for new wave using Naive Bayes: 0.99 \n",
      "Precision for new wave using Naive Bayes: 0.12 \n",
      "Accuracy for punk using Naive Bayes: 0.98 \n",
      "Precision for punk using Naive Bayes: 0.21 \n",
      "Accuracy for neo mellow using Naive Bayes: 0.95 \n",
      "Precision for neo mellow using Naive Bayes: 0.04 \n",
      "Accuracy for contemporary country using Naive Bayes: 0.99 \n",
      "Precision for contemporary country using Naive Bayes: 0.17 \n",
      "Accuracy for alternative hip hop using Naive Bayes: 0.95 \n",
      "Precision for alternative hip hop using Naive Bayes: 0.12 \n",
      "Accuracy for nuevo regional mexicano using Naive Bayes: 0.95 \n",
      "Precision for nuevo regional mexicano using Naive Bayes: 0.07 \n",
      "Accuracy for big band using Naive Bayes: 0.93 \n",
      "Precision for big band using Naive Bayes: 0.04 \n",
      "Accuracy for new jack swing using Naive Bayes: 0.93 \n",
      "Precision for new jack swing using Naive Bayes: 0.05 \n",
      "Accuracy for rock-and-roll using Naive Bayes: 0.98 \n",
      "Precision for rock-and-roll using Naive Bayes: 0.11 \n",
      "Accuracy for bubblegum pop using Naive Bayes: 0.97 \n",
      "Precision for bubblegum pop using Naive Bayes: 0.12 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "\n",
    "# Assuming you have 'train_df' DataFrame with features and 'genres' as the target variable\n",
    "\n",
    "# Iterate over all unique genres\n",
    "for genre_of_interest in train_df['genres'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    train_df['target'] = (train_df['genres'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "    y = train_df['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    artists_encoded_train = X_train[['Artists_encoded', 'key', 'mode']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded', 'key', 'mode']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_valid\n",
    "\n",
    "    X_train_scaled1 = X_train_scaled.drop(columns=['mode', 'energy'])\n",
    "    X_valid_scaled1 = X_valid_scaled.drop(columns=['mode', 'energy'])\n",
    "\n",
    "    # Check if the data is textual or numerical\n",
    "    is_text_data = isinstance(X_train_scaled1.iloc[0, 0], str)\n",
    "\n",
    "    # Initialize the Naive Bayes classifier\n",
    "    if is_text_data:\n",
    "        naive_bayes_classifier = MultinomialNB()\n",
    "    else:\n",
    "        naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    naive_bayes_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = naive_bayes_classifier.predict(X_valid_scaled1)\n",
    "\n",
    "    # Evaluate the performance on the test set\n",
    "    accuracy_test = accuracy_score(y_valid, y_pred_test)\n",
    "    precision_test = precision_score(y_valid, y_pred_test)\n",
    "    print(f'Accuracy for {genre_of_interest} using Naive Bayes: {accuracy_test:.2f} ')\n",
    "    print(f'Precision for {genre_of_interest} using Naive Bayes: {precision_test:.2f} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: 0, Count: 16229\n",
      "Genre: 1, Count: 102\n"
     ]
    }
   ],
   "source": [
    "genre_counts = y_train.value_counts()\n",
    "\n",
    "# Print the count for each genre\n",
    "for genre, count in genre_counts.items():\n",
    "    print(f'Genre: {genre}, Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on Validation Set (XGBoost): 0.99\n",
      "\n",
      "Classification Report on Validation Set (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4059\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "Weighted Precision on Validation Set (XGBoost): 0.99\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier on the training set\n",
    "xgb_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_valid_xgb = xgb_classifier.predict(X_valid_scaled1)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid_xgb = accuracy_score(y_valid, y_pred_valid_xgb)\n",
    "print(f'Accuracy on Validation Set (XGBoost): {accuracy_valid_xgb:.2f}')\n",
    "\n",
    "# Display additional evaluation metrics for XGBoost\n",
    "print('\\nClassification Report on Validation Set (XGBoost):')\n",
    "print(classification_report(y_valid, y_pred_valid_xgb))\n",
    "\n",
    "# Calculate and print precision and recall for XGBoost\n",
    "precision_xgb = precision_score(y_valid, y_pred_valid_xgb, average='weighted')\n",
    "print(f'Weighted Precision on Validation Set (XGBoost): {precision_xgb:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy for dance rock using XGBoost: 0.99\n",
      "Classification Report for dance rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4048\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classic rock using XGBoost: 0.99\n",
      "Classification Report for classic rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4036\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dance pop using XGBoost: 0.98\n",
      "Classification Report for dance pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3987\n",
      "           1       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.95      0.98      0.96      4083\n",
      "\n",
      "[12:23:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop punk using XGBoost: 0.99\n",
      "Classification Report for pop punk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4051\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for modern alternative rock using XGBoost: 0.99\n",
      "Classification Report for modern alternative rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4058\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for traditional folk using XGBoost: 0.99\n",
      "Classification Report for traditional folk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4055\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for roots rock using XGBoost: 0.99\n",
      "Classification Report for roots rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4034\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop using XGBoost: 0.98\n",
      "Classification Report for pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3990\n",
      "           1       0.20      0.02      0.04        93\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.59      0.51      0.51      4083\n",
      "weighted avg       0.96      0.98      0.97      4083\n",
      "\n",
      "[12:23:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for indie rock using XGBoost: 0.98\n",
      "Classification Report for indie rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4033\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.98      0.98      4083\n",
      "\n",
      "[12:23:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for country road using XGBoost: 0.99\n",
      "Classification Report for country road using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4052\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hip hop using XGBoost: 0.98\n",
      "Classification Report for hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4018\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:23:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for southern hip hop using XGBoost: 0.98\n",
      "Classification Report for southern hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4021\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:23:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for adult standards using XGBoost: 0.98\n",
      "Classification Report for adult standards using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4014\n",
      "           1       0.09      0.01      0.03        69\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.54      0.51      0.51      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:23:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop rock using XGBoost: 0.99\n",
      "Classification Report for pop rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4031\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.99      0.98      4083\n",
      "\n",
      "[12:23:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for album rock using XGBoost: 0.98\n",
      "Classification Report for album rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4020\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:23:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for nu metal using XGBoost: 0.99\n",
      "Classification Report for nu metal using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4048\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dirty south rap using XGBoost: 0.99\n",
      "Classification Report for dirty south rap using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4060\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for electro house using XGBoost: 0.99\n",
      "Classification Report for electro house using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4063\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for cool jazz using XGBoost: 0.99\n",
      "Classification Report for cool jazz using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4052\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for brill building pop using XGBoost: 0.99\n",
      "Classification Report for brill building pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4049\n",
      "           1       0.10      0.03      0.05        34\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.55      0.51      0.52      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for trap using XGBoost: 0.98\n",
      "Classification Report for trap using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4024\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:23:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for disco using XGBoost: 0.99\n",
      "Classification Report for disco using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4048\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hip pop using XGBoost: 0.99\n",
      "Classification Report for hip pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4042\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for alternative rock using XGBoost: 0.98\n",
      "Classification Report for alternative rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4022\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:23:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for corrido using XGBoost: 0.98\n",
      "Classification Report for corrido using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4049\n",
      "           1       0.03      0.03      0.03        34\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.51      0.51      0.51      4083\n",
      "weighted avg       0.98      0.98      0.98      4083\n",
      "\n",
      "[12:23:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rock using XGBoost: 0.97\n",
      "Classification Report for rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3988\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.97      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.95      0.97      0.96      4083\n",
      "\n",
      "[12:23:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for latin hip hop using XGBoost: 0.99\n",
      "Classification Report for latin hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4057\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for edm using XGBoost: 0.98\n",
      "Classification Report for edm using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4033\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.98      0.98      4083\n",
      "\n",
      "[12:23:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for art rock using XGBoost: 0.99\n",
      "Classification Report for art rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4037\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for tropical using XGBoost: 0.99\n",
      "Classification Report for tropical using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4041\n",
      "           1       0.20      0.07      0.11        42\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.60      0.53      0.55      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for r&b using XGBoost: 0.99\n",
      "Classification Report for r&b using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4035\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for country rock using XGBoost: 0.98\n",
      "Classification Report for country rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4017\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:23:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ccm using XGBoost: 1.00\n",
      "Classification Report for ccm using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4063\n",
      "           1       0.60      0.15      0.24        20\n",
      "\n",
      "    accuracy                           1.00      4083\n",
      "   macro avg       0.80      0.57      0.62      4083\n",
      "weighted avg       0.99      1.00      0.99      4083\n",
      "\n",
      "[12:23:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classic uk pop using XGBoost: 0.99\n",
      "Classification Report for classic uk pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4053\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for latin using XGBoost: 0.98\n",
      "Classification Report for latin using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4019\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:23:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for movie tunes using XGBoost: 0.99\n",
      "Classification Report for movie tunes using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4056\n",
      "           1       0.14      0.04      0.06        27\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.57      0.52      0.53      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hard rock using XGBoost: 0.99\n",
      "Classification Report for hard rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4040\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for jazz using XGBoost: 0.99\n",
      "Classification Report for jazz using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4046\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for blues rock using XGBoost: 0.99\n",
      "Classification Report for blues rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4050\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gangster rap using XGBoost: 0.99\n",
      "Classification Report for gangster rap using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4029\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.99      0.98      4083\n",
      "\n",
      "[12:23:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop dance using XGBoost: 0.99\n",
      "Classification Report for pop dance using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4038\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:23:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for underground hip hop using XGBoost: 0.99\n",
      "Classification Report for underground hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4051\n",
      "           1       0.25      0.12      0.17        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.62      0.56      0.58      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for electronica using XGBoost: 0.99\n",
      "Classification Report for electronica using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4049\n",
      "           1       0.43      0.09      0.15        34\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.71      0.54      0.57      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for psychedelic rock using XGBoost: 0.99\n",
      "Classification Report for psychedelic rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4048\n",
      "           1       0.12      0.03      0.05        35\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.56      0.51      0.52      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for soul jazz using XGBoost: 0.99\n",
      "Classification Report for soul jazz using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4055\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for show tunes using XGBoost: 0.99\n",
      "Classification Report for show tunes using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4059\n",
      "           1       0.27      0.17      0.21        24\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.63      0.58      0.60      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for new americana using XGBoost: 0.99\n",
      "Classification Report for new americana using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4057\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for folk using XGBoost: 0.99\n",
      "Classification Report for folk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4057\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:23:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for electropop using XGBoost: 0.99\n",
      "Classification Report for electropop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4044\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:23:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for urban contemporary using XGBoost: 0.98\n",
      "Classification Report for urban contemporary using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4023\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for bebop using XGBoost: 0.99\n",
      "Classification Report for bebop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4055\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for alternative metal using XGBoost: 0.98\n",
      "Classification Report for alternative metal using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4029\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for folk rock using XGBoost: 0.98\n",
      "Classification Report for folk rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4024\n",
      "           1       0.00      0.00      0.00        59\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for modern rock using XGBoost: 0.98\n",
      "Classification Report for modern rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4011\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:24:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for contemporary post-bop using XGBoost: 0.99\n",
      "Classification Report for contemporary post-bop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4060\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hard bop using XGBoost: 0.99\n",
      "Classification Report for hard bop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4061\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for indie folk using XGBoost: 0.99\n",
      "Classification Report for indie folk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4051\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for post-teen pop using XGBoost: 0.98\n",
      "Classification Report for post-teen pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4025\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for quiet storm using XGBoost: 0.99\n",
      "Classification Report for quiet storm using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4039\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for country using XGBoost: 0.98\n",
      "Classification Report for country using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4032\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.98      0.98      4083\n",
      "\n",
      "[12:24:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hollywood using XGBoost: 0.99\n",
      "Classification Report for hollywood using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4054\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for pop rap using XGBoost: 0.98\n",
      "Classification Report for pop rap using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4006\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.96      0.98      0.97      4083\n",
      "\n",
      "[12:24:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for tropical house using XGBoost: 0.99\n",
      "Classification Report for tropical house using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4057\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for soul using XGBoost: 0.99\n",
      "Classification Report for soul using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4043\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classic soul using XGBoost: 0.99\n",
      "Classification Report for classic soul using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4042\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for filmi using XGBoost: 1.00\n",
      "Classification Report for filmi using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4066\n",
      "           1       0.80      0.24      0.36        17\n",
      "\n",
      "    accuracy                           1.00      4083\n",
      "   macro avg       0.90      0.62      0.68      4083\n",
      "weighted avg       1.00      1.00      1.00      4083\n",
      "\n",
      "[12:24:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for neo soul using XGBoost: 0.99\n",
      "Classification Report for neo soul using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4063\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for lounge using XGBoost: 0.99\n",
      "Classification Report for lounge using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4053\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rap using XGBoost: 0.97\n",
      "Classification Report for rap using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3992\n",
      "           1       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.97      4083\n",
      "   macro avg       0.49      0.50      0.49      4083\n",
      "weighted avg       0.96      0.97      0.96      4083\n",
      "\n",
      "[12:24:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for jazz funk using XGBoost: 0.99\n",
      "Classification Report for jazz funk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4052\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for indie pop using XGBoost: 0.99\n",
      "Classification Report for indie pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4043\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for metal using XGBoost: 0.99\n",
      "Classification Report for metal using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4055\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for motown using XGBoost: 0.99\n",
      "Classification Report for motown using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4051\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for regional mexican using XGBoost: 0.98\n",
      "Classification Report for regional mexican using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4026\n",
      "           1       0.09      0.04      0.05        57\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.54      0.52      0.52      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for funk using XGBoost: 0.98\n",
      "Classification Report for funk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4017\n",
      "           1       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.98      4083\n",
      "\n",
      "[12:24:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classical using XGBoost: 0.99\n",
      "Classification Report for classical using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4050\n",
      "           1       0.50      0.30      0.38        33\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.75      0.65      0.69      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for classical performance using XGBoost: 0.99\n",
      "Classification Report for classical performance using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4042\n",
      "           1       0.58      0.54      0.56        41\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.79      0.77      0.78      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for indie poptimism using XGBoost: 0.99\n",
      "Classification Report for indie poptimism using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4058\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for mellow gold using XGBoost: 0.98\n",
      "Classification Report for mellow gold using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      4013\n",
      "           1       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.98      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.98      0.97      4083\n",
      "\n",
      "[12:24:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for vocal jazz using XGBoost: 0.99\n",
      "Classification Report for vocal jazz using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4060\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rock en espanol using XGBoost: 0.99\n",
      "Classification Report for rock en espanol using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4052\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for stomp and holler using XGBoost: 0.99\n",
      "Classification Report for stomp and holler using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4050\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for hardcore hip hop using XGBoost: 0.99\n",
      "Classification Report for hardcore hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4055\n",
      "           1       0.08      0.04      0.05        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.54      0.52      0.52      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for new romantic using XGBoost: 0.99\n",
      "Classification Report for new romantic using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4061\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for latin pop using XGBoost: 0.99\n",
      "Classification Report for latin pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4051\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.99      4083\n",
      "\n",
      "[12:24:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for reggaeton using XGBoost: 0.99\n",
      "Classification Report for reggaeton using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4055\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for new wave pop using XGBoost: 0.99\n",
      "Classification Report for new wave pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4028\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.99      0.98      4083\n",
      "\n",
      "[12:24:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for post-disco using XGBoost: 0.99\n",
      "Classification Report for post-disco using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4051\n",
      "           1       0.11      0.03      0.05        32\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.55      0.51      0.52      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for soft rock using XGBoost: 0.99\n",
      "Classification Report for soft rock using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4028\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.97      0.99      0.98      4083\n",
      "\n",
      "[12:24:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for trap latino using XGBoost: 0.99\n",
      "Classification Report for trap latino using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4058\n",
      "           1       0.06      0.04      0.05        25\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.53      0.52      0.52      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for new wave using XGBoost: 0.99\n",
      "Classification Report for new wave using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4058\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for punk using XGBoost: 0.99\n",
      "Classification Report for punk using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4049\n",
      "           1       0.27      0.12      0.16        34\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.63      0.56      0.58      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for neo mellow using XGBoost: 0.99\n",
      "Classification Report for neo mellow using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4064\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for contemporary country using XGBoost: 0.99\n",
      "Classification Report for contemporary country using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4042\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.49      0.50      0.50      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for alternative hip hop using XGBoost: 0.99\n",
      "Classification Report for alternative hip hop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4042\n",
      "           1       0.10      0.02      0.04        41\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.55      0.51      0.52      4083\n",
      "weighted avg       0.98      0.99      0.98      4083\n",
      "\n",
      "[12:24:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for nuevo regional mexicano using XGBoost: 0.99\n",
      "Classification Report for nuevo regional mexicano using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4058\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for big band using XGBoost: 0.99\n",
      "Classification Report for big band using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4063\n",
      "           1       0.33      0.05      0.09        20\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.66      0.52      0.54      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for new jack swing using XGBoost: 0.99\n",
      "Classification Report for new jack swing using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4060\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for rock-and-roll using XGBoost: 0.99\n",
      "Classification Report for rock-and-roll using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4053\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n",
      "[12:24:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for bubblegum pop using XGBoost: 0.99\n",
      "Classification Report for bubblegum pop using XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4059\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.99      4083\n",
      "   macro avg       0.50      0.50      0.50      4083\n",
      "weighted avg       0.99      0.99      0.99      4083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Assuming train_df is your DataFrame containing the dataset\n",
    "\n",
    "for genre_of_interest in train_df['genres'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    train_df['target'] = (train_df['genres'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = train_df.drop(columns=['genres', 'target'])  # Features\n",
    "    y = train_df['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    artists_encoded_train = X_train[['Artists_encoded', 'key', 'mode']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded', 'key', 'mode']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded', 'key', 'mode'])\n",
    "\n",
    "    # Scale the features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded', 'key', 'mode']] = artists_encoded_valid\n",
    "\n",
    "    # Drop 'mode' and 'energy' columns\n",
    "    X_train_scaled1 = X_train_scaled.drop(columns=['mode', 'energy'])\n",
    "    X_valid_scaled1 = X_valid_scaled.drop(columns=['mode', 'energy'])\n",
    "\n",
    "    # Initialize the XGBoost classifier\n",
    "    xgb_classifier = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "    # Train the XGBoost classifier on the training set\n",
    "    xgb_classifier.fit(X_train_scaled1, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_valid_xgb = xgb_classifier.predict(X_valid_scaled1)\n",
    "\n",
    "    # Evaluate the performance on the validation set\n",
    "    accuracy_valid_xgb = accuracy_score(y_valid, y_pred_valid_xgb)\n",
    "    print(f'Accuracy for {genre_of_interest} using XGBoost: {accuracy_valid_xgb:.2f}')\n",
    "\n",
    "    # Display additional evaluation metrics for XGBoost\n",
    "    print(f'Classification Report for {genre_of_interest} using XGBoost:')\n",
    "    print(classification_report(y_valid, y_pred_valid_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=3: Additional Validation Set: 0.46\n",
      "Accuracy for k=5: Additional Validation Set: 0.45\n",
      "Accuracy for k=7: Additional Validation Set: 0.42\n",
      "Accuracy for k=9: Additional Validation Set: 0.41\n",
      "Accuracy for k=11: Additional Validation Set: 0.39\n",
      "Accuracy for k=13: Additional Validation Set: 0.39\n",
      "Accuracy for k=15: Additional Validation Set: 0.38\n",
      "Accuracy for k=17: Additional Validation Set: 0.37\n",
      "Accuracy for k=19: Additional Validation Set: 0.37\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
    "\n",
    "trained_scaled2=pd.read_csv('X_train_scaled2.csv')\n",
    "X_train2 = trained_scaled2.drop(columns=['genre'])\n",
    "y_train2 = trained_scaled2['genre']\n",
    "\n",
    "valid_scaled2=pd.read_csv('X_valid_scaled2.csv')\n",
    "X_valid2 = valid_scaled2.drop(columns=['genre'])\n",
    "y_valid2 = valid_scaled2['genre']\n",
    "\n",
    "k_values = [3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "\n",
    "for k in k_values:\n",
    "    # Initialize the KNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    knn_classifier.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "    # Make predictions on the additional validation set\n",
    "    y_pred_val1 = knn_classifier.predict(X_valid2)\n",
    "    accuracy_val1 = accuracy_score(y_valid2, y_pred_val1)\n",
    "    #precision_val1=precision_score(y_valid2, y_pred_val1)\n",
    "    \n",
    "\n",
    "    # Print the performance for each k on both test and additional validation sets\n",
    "    print(f'Accuracy for k={k}: Additional Validation Set: {accuracy_val1:.2f}')\n",
    "    '''print('\\nClassification Report:')\n",
    "    print(classification_report(y_valid, y_pred_val1))\n",
    "    print('\\n---------------------------\\n')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Jazz and Blues: 0.91,Precision: 0.63\n",
      "Accuracy for Pop and Dance: 0.71,Precision: 0.53\n",
      "Accuracy for Country and Americana: 0.88,Precision: 0.30\n",
      "Accuracy for Hip Hop and Rap: 0.88,Precision: 0.63\n",
      "Accuracy for Soul, R&B, and Related Genres: 0.90,Precision: 0.27\n",
      "Accuracy for Rock and Alternative: 0.80,Precision: 0.50\n",
      "Accuracy for Latin, Tropical, and Regional Varieties: 0.94,Precision: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = trained_scaled2.drop(columns=['genre'])  # Features\n",
    "\n",
    "# Iterate over all unique genres\n",
    "for genre_of_interest in trained_scaled2['genre'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    trained_scaled2['target'] = (trained_scaled2['genre'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = trained_scaled2.drop(columns=['genre', 'target'])  # Features\n",
    "    y = trained_scaled2['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    artists_encoded_train = X_train[['Artists_encoded','key']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded','key']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded','key'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded','key'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded','key']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded','key']] = artists_encoded_valid\n",
    "   \n",
    "    # Initialize the KNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Adjust k as needed\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = knn_classifier.predict(X_valid_scaled)\n",
    "\n",
    "    # Evaluate the performance on the test set\n",
    "    accuracy_test = accuracy_score(y_valid, y_pred_test)\n",
    "    precision_test = precision_score(y_valid, y_pred_test)\n",
    "    \n",
    "    print(f'Accuracy for {genre_of_interest}: {accuracy_test:.2f},Precision: {precision_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.48\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                  Country and Americana       0.32      0.17      0.22       443\n",
      "                        Hip Hop and Rap       0.57      0.75      0.65       624\n",
      "                         Jazz and Blues       0.54      0.59      0.56       481\n",
      "Latin, Tropical, and Regional Varieties       0.46      0.36      0.40       272\n",
      "                          Pop and Dance       0.43      0.52      0.47      1314\n",
      "                   Rock and Alternative       0.50      0.52      0.51       913\n",
      "          Soul, R&B, and Related Genres       0.34      0.09      0.14       385\n",
      "\n",
      "                               accuracy                           0.48      4432\n",
      "                              macro avg       0.45      0.43      0.42      4432\n",
      "                           weighted avg       0.46      0.48      0.46      4432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "adaboost_classifier.fit(X_train2, y_train2)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_valid = adaboost_classifier.predict(X_valid2)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid = accuracy_score(y_valid2, y_pred_valid)\n",
    "print(f'Accuracy on Validation Set: {accuracy_valid:.2f}')\n",
    "\n",
    "# Display additional evaluation metrics\n",
    "print('\\nClassification Report on Validation Set:')\n",
    "print(classification_report(y_valid2, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Jazz and Blues: 0.91,Precision: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Pop and Dance: 0.71,Precision: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Country and Americana: 0.89,Precision: 0.33\n",
      "Accuracy for Hip Hop and Rap: 0.91,Precision: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Soul, R&B, and Related Genres: 0.91,Precision: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/saranyak/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-26582f4b3ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Train the AdaBoost classifier on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0madaboost_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \"\"\"\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "import pandas as pd\n",
    "\n",
    "X = trained_scaled2.drop(columns=['genre'])  # Features\n",
    "\n",
    "# Iterate over all unique genres\n",
    "for genre_of_interest in trained_scaled2['genre'].unique():\n",
    "    # Create a binary target variable for one-vs-all classification\n",
    "    trained_scaled2['target'] = (trained_scaled2['genre'] == genre_of_interest).astype(int)\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = trained_scaled2.drop(columns=['genre', 'target'])  # Features\n",
    "    y = trained_scaled2['target']  # Binary target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    artists_encoded_train = X_train[['Artists_encoded','key']]\n",
    "    artists_encoded_valid = X_valid[['Artists_encoded','key']]\n",
    "    X_train = X_train.drop(columns=['Artists_encoded','key'])\n",
    "    X_valid = X_valid.drop(columns=['Artists_encoded','key'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_valid_scaled = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "\n",
    "    artists_encoded_train = artists_encoded_train.reset_index(drop=True)\n",
    "    artists_encoded_valid = artists_encoded_valid.reset_index(drop=True)\n",
    "\n",
    "    X_train_scaled[['Artists_encoded','key']] = artists_encoded_train\n",
    "    X_valid_scaled[['Artists_encoded','key']] = artists_encoded_valid\n",
    "    \n",
    "    param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5, 1.0]}\n",
    "    adaboost_classifier = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, scoring='precision', cv=5)\n",
    "\n",
    "    # Train the AdaBoost classifier on the training set\n",
    "    adaboost_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = adaboost_classifier.predict(X_valid_scaled)\n",
    "\n",
    "    # Evaluate the precision on the test set\n",
    "    precision_test = precision_score(y_valid, y_pred_test)\n",
    "    accuracy_test = accuracy_score(y_valid, y_pred_test)\n",
    "    print(f'Accuracy for {genre_of_interest}: {accuracy_test:.2f},Precision: {precision_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try XGBoost\n",
    "# Test set\n",
    "# Test set from joel\n",
    "# Newly generated dataset for these classifiers\n",
    "# Check precision how good they are, classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
